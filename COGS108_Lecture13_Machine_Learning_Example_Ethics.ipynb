{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 13: ML Examples and Ethics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What features distinguish a house in New York from a house in San Francisco?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, some intuition\n",
    "\n",
    "Lets say you had to determine whether a home is in San Franciso or in New York. In machine learning terms, categorizing data points is a **classification task**.\n",
    "\n",
    "* San Francisco is hilly... so elevation may be a helpful feature\n",
    "* With the data here, homes >~73m should be classified as San Francisco homes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding nuance\n",
    "\n",
    "Additing another **dimension** allows for more nuance. For example, New York apartments can be extremely expensive per square foot.\n",
    "\n",
    "So visualizating elevation and price per square foot in a **Scatterplot** helps us distinguish lower elevation homes.\n",
    "\n",
    "The data suggests that, among homes at or below 73 meters, those that cost more than $19,116.7 per square meter are in New York City.\n",
    "\n",
    "Dimensions in a data set are called **features**, **predictors**, or **variables**.\n",
    "\n",
    "* Elevation isn't a perfect feature for classification, so we can look at its relationship to other features, like *price per square foot*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing boundaries\n",
    "\n",
    "Boundaries can be drawn so that if a house falls in the *green box*, it's classified as a San Francisco home. Blue box, New York. Statistical learning figures out how to best draw these boxes.\n",
    "\n",
    "Our training set will use 7 different **features**. A **scatterplot matrix of the relationship between these values can define these. Patterns are clear, but boundaries for delineationa are not obvious."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now, machine learning\n",
    "\n",
    "Determining the best boundary is where **machine learning** comes in.\n",
    "\n",
    "**Decision trees** are one example of machine learning method for classification tasks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding better boundaries\n",
    "\n",
    "We guessed ~73m before. Let's improve on that guess...\n",
    "\n",
    "A **histogram** helps display frequency of homes by elevation more easily.\n",
    "\n",
    "73m is the highest home in New York, but most of them have lower elevations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your first fork\n",
    "\n",
    "A decision tree uses if-then statements to define patterns in the data.\n",
    "\n",
    "In machine learning, the splits are called **forks** and they split the data into branches based on some value.\n",
    "\n",
    "The value that splits the branches is the **split point**. Homes to the left get categorized differently then than those on the right."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tradeoffs\n",
    "\n",
    "Splitting at ~73m incorrectly classifies some San Francisco homes as New York homes.\n",
    "\n",
    "San Francisco homes that were misclassifies are **false negatives**.\n",
    "\n",
    "If you split to capture *every* home in San Francisco, you'll also get a bunch of New York homes (**false positives**)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best split\n",
    "\n",
    "The best split point aims for branches that are as homogenous (pure) as possible."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursion\n",
    "\n",
    "Additional split points are determined through repetition (recursion)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Growing a tree\n",
    "\n",
    "Addtional forks add new information to improve **prediction accuracy**.\n",
    "\n",
    "Adding serveral more layers gets our example model accuracy up to 96%.\n",
    "\n",
    "It's possible to add branches until your model is **100% accurate**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions\n",
    "\n",
    "The decision tree **model** can then predict which homes are in which city.\n",
    "\n",
    "Here, we're using the **training data**.\n",
    "\n",
    "Because our tree was trained on this data and we grew the tree to 100% accracy, each house is perfectly sorted."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reality check\n",
    "\n",
    "But... how does this tree do on the data that the model hasn't seen before?\n",
    "\n",
    "The *test set* then makes its way through the decision tree.\n",
    "\n",
    "Ideally the tree should perform similarly on both known and unknown data.\n",
    "\n",
    "These errors are due to **overfitting**. Fitting every single detail in the training data led to a tree that modeled unimportant features, that did not allow for similar accracy in new data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap\n",
    "\n",
    "1. Machine learning identifies patterns using **statistical learning** and computers by unearthing **boundaries** in data sets. You can use it to make predictions.\n",
    "2. One method for making predictions is called a decsion tree, which uses a series of if-then statements to identify boundaries and define patterns in the data.\n",
    "3. **Overfitting** happens when some boundaries are based on *distinctions that don't make a difference*. YOu can see if a model overfits by having test data flow through the model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Can Be Done About Overfitting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias-Variance Tradeoff\n",
    "\n",
    "* **High variance** models make mistakes in *inconsistent* ways\n",
    "* **Biased models** tend to be overly simple and not reflect reality\n",
    "* What to do:\n",
    "    * Consider tuning parameters in the model\n",
    "        * can avoid overfitting by setting minimum node size threshold (fewer splits, variance decreased)\n",
    "    * Changing model approach\n",
    "        * Bagging, boosting, and ensemble methods\n",
    "    * Reconsider data splitting approach\n",
    "        * Training + test?\n",
    "        * LOOCV\n",
    "        * K-fold CV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we determine what that function (`f`) *is* using these data?\n",
    "\n",
    "* $y = f(x) + noise$\n",
    "    * Linear regression\n",
    "    * Quadratic regression\n",
    "    * Piecewise linear nonparametric regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data Parition Method\n",
    "\n",
    "1. Randomly choose 30% of the data to be in a **test set**\n",
    "2. The remainder is a **training set**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model on your **training set**\n",
    "\n",
    "3. Perform your regression on the training set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess future performance using the **test set**\n",
    "\n",
    "4. Estimate your future performance with the test set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go through this process for each possible model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pros and Cons of Data Partitioning\n",
    "\n",
    "* Pros\n",
    "    * Simple approach\n",
    "    * can choose model with best test-set socre\n",
    "* Cons\n",
    "    * Model fit on 30% less data than you have\n",
    "    * Without a large data set, removing 30% of the data could bias prediction\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave Out One Cross Validation (LOOCV)\n",
    "\n",
    "For $k=1$ to $R$:\n",
    "\n",
    "1. Let $(x_k, y_k)$ be the $k^{th}$ record\n",
    "2. Temporarily remove $(x_k, y_k)$ from the dataset\n",
    "3. Train on the remaining $R-1$ datapoints\n",
    "4. Note your error $(x_k, y_k)$\n",
    "\n",
    "When you've done all the points, report the mean error."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method Comparison\n",
    "\n",
    "**Data Partitioning**\n",
    "\n",
    "* Pros: Cheap\n",
    "* Cons: Variance, unreliable estimate of future performance\n",
    "\n",
    "**LOOCV**\n",
    "\n",
    "* Pros: Uses all your data\n",
    "* Cons: Computationally expensive, has weird behavior"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Fold Cross Validation\n",
    "\n",
    "* For the red partition: Train on all the points not in the red partition. Find the test-set sum of errors on the red points.\n",
    "* For the green partition: Train on all the points not in the green partition. Find the test-set sum of errors on the green points.\n",
    "* For the blue partition: Train on all the points not in the green partition. Find the test-set sum of errors on the blue points.\n",
    "\n",
    "Then report the mean error."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CLICKER QUESTION**\n",
    "\n",
    "Given the example we just worked, how would you model these data?\n",
    "\n",
    "A) Linear regression ($MSE_{3fold} = 2.05$)\n",
    "\n",
    "**B) Quadratic regression ($MSE_{3fold} = 1.11$)**\n",
    "\n",
    "C) Pairwise linear nonparametric regression ($MSE_{3fold} = 2.93$)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CLICKER QUESTION**\n",
    "\n",
    "Which approach would you use to limit overfitting?\n",
    "\n",
    "A) Data partitioning\n",
    "\n",
    "B) LOOCV\n",
    "\n",
    "C) k-fold CV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Analysis Ethics\n",
    "\n",
    "When models are trained on historical data, predictions will perpetuate historical biases."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What to do about bias\n",
    "\n",
    "1. Anticipate and plan for potential biases before model generation. Check for biases after.\n",
    "2. Have diverse teams.\n",
    "3. Use machine learning to improve lives rather than for punitive purposes.\n",
    "4. Revisit your models. Update your algorithms.\n",
    "5. You are responsible for the models you put out into the world, unintended consequences and all."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussed so far...\n",
    "\n",
    "* Data partitioning\n",
    "* Feature selection\n",
    "* Supervised and unsupervised machine learning\n",
    "    * Continuous variables: regression (supervised) and dimensionality reduction (unsupervised)\n",
    "    * Categorical variables: classification (supervised, decision trees) or clustering (unsupervised)\n",
    "* Model assessement\n",
    "    * Continuous: RMSE (and Accuracy)\n",
    "    * Categorical: Accuracy, Sensitivity, Specificity, AUC\n",
    "* Biased data can and will lead to biased predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Approach\n",
    "\n",
    "Which would be the most predictive of your future success?\n",
    "\n",
    "A) Grade in COGS 108\n",
    "\n",
    "B) COGS 108 attendance\n",
    "\n",
    "C) Gender\n",
    "\n",
    "D) Hair color\n",
    "\n",
    "E) Something else"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 254\n",
    "\n",
    "Train the model: N = 178 (70% of the data) - train the model\n",
    "\n",
    "Test the model: N = 76 (30% of the data) - predicted success in test set\n",
    "\n",
    "Assess the prediction model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Think about whether the models you're building should even be built."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive algorithms should (*at a minimum*) be FAT\n",
    "\n",
    "* Fair: Lacking biases which create unfair and discriminatory outcomes\n",
    "    * For whom does this algorithm fail?\n",
    "    * Steps to take:\n",
    "        1. Verify data about individual is correct\n",
    "        2. Carry out \"sensitivity test\"\n",
    "* Accountable/Accrate: Answerable to the people subject to them\n",
    "    * Correct data used? Is there a mechanism for appeal?\n",
    "* Transparent: Open about how and why particular decisions were made\n",
    "    * Think carefully about what transparency is (handing over source code likely isn't the answer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *A Mulching Proposal: Analyzing and Improving an Algorithmic System for Turning the Elderly into High-Nutrient Slurry* (Keyes et al., 2019)\n",
    "\n",
    "https://dl.acm.org/doi/10.1145/3290607.3310433\n",
    "\n",
    "* Fair: Equally considers all elderly individuals\n",
    "* Accurate: Pre = Has mechanism for appeal; Post = Compensation\n",
    "* Transparent: Website with all features, testable\n",
    "\n",
    "Checklists are helpful, but they're not excuse for thoughtlessness."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
